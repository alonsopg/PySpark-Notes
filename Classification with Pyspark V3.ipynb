{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with PySpark\n",
    "\n",
    "For this notebook I am using a simple sentiment analisys dataset just to show a classification pipeline with PySpark. This dataset is the same I used for my bachelor of science thesis degree. Indeed, this classification pipeline can be used with other datasets.\n",
    "\n",
    "Firstly, let's show the data, with the help of pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEG_Electrolux_60840_Lavamat__Opinion_1506705</td>\n",
       "      <td>programa especial ropa sensible planchado fáci...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEG_Electrolux_62610_Lavamat__Opinion_2000923</td>\n",
       "      <td>carga superior punto medio color blanco carga ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEG_Electrolux_L14800VI__Opinion_2005396</td>\n",
       "      <td>carga superior forma frontal programa majo efi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEG_Electrolux_L6227FL__Opinion_2140710</td>\n",
       "      <td>modelo electrolux</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEG_Electrolux_L62280FL__Opinion_2151025</td>\n",
       "      <td>clasificación energético sonido bajo conversac...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AEG_Electrolux_L62642VI__Opinion_1995158</td>\n",
       "      <td>ficha tecnica programa especial prenda delicado</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AEG_Electrolux_L62642VI__Opinion_1995791</td>\n",
       "      <td>habitación principal control electrónico clasi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AEG_Electrolux_L70470FL__Opinion_2085167</td>\n",
       "      <td>clasificación energético fase anterior lavado ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AEG_Electrolux_L74650__Opinion_1856967</td>\n",
       "      <td>capazidad grande</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEG_Electrolux_L85275XFL__Opinion_2138100</td>\n",
       "      <td>temperatura medio ciclo medio factor determina...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  \\\n",
       "0  AEG_Electrolux_60840_Lavamat__Opinion_1506705   \n",
       "1  AEG_Electrolux_62610_Lavamat__Opinion_2000923   \n",
       "2       AEG_Electrolux_L14800VI__Opinion_2005396   \n",
       "3        AEG_Electrolux_L6227FL__Opinion_2140710   \n",
       "4       AEG_Electrolux_L62280FL__Opinion_2151025   \n",
       "5       AEG_Electrolux_L62642VI__Opinion_1995158   \n",
       "6       AEG_Electrolux_L62642VI__Opinion_1995791   \n",
       "7       AEG_Electrolux_L70470FL__Opinion_2085167   \n",
       "8         AEG_Electrolux_L74650__Opinion_1856967   \n",
       "9      AEG_Electrolux_L85275XFL__Opinion_2138100   \n",
       "\n",
       "                                             content  label  \n",
       "0  programa especial ropa sensible planchado fáci...      5  \n",
       "1  carga superior punto medio color blanco carga ...      4  \n",
       "2  carga superior forma frontal programa majo efi...      5  \n",
       "3                                  modelo electrolux      4  \n",
       "4  clasificación energético sonido bajo conversac...      4  \n",
       "5    ficha tecnica programa especial prenda delicado      5  \n",
       "6  habitación principal control electrónico clasi...      4  \n",
       "7  clasificación energético fase anterior lavado ...      4  \n",
       "8                                   capazidad grande      3  \n",
       "9  temperatura medio ciclo medio factor determina...      5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/user/Jupyter/ml_notes/PySpark-Notes/datasets/simple_corpus.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to the above dataframe, we can se that it is conformed of 3 columns (`id`, `content` and `label`), note that pandas adds an index column at the first position. Next, we proceed to transform the pandas dataframe to a spark dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|                  id|             content|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|AEG_Electrolux_60...|programa especial...|    5|\n",
      "|AEG_Electrolux_62...|carga superior pu...|    4|\n",
      "|AEG_Electrolux_L1...|carga superior fo...|    5|\n",
      "|AEG_Electrolux_L6...|   modelo electrolux|    4|\n",
      "|AEG_Electrolux_L6...|clasificaciÃ³n en...|    4|\n",
      "|AEG_Electrolux_L6...|ficha tecnica pro...|    5|\n",
      "|AEG_Electrolux_L6...|habitaciÃ³n princ...|    4|\n",
      "|AEG_Electrolux_L7...|clasificaciÃ³n en...|    4|\n",
      "|AEG_Electrolux_L7...|    capazidad grande|    3|\n",
      "|AEG_Electrolux_L8...|temperatura medio...|    5|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "spark_df = sqlContext.createDataFrame(df[['id', 'content', 'label']])\n",
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=u'AEG_Electrolux_60840_Lavamat__Opinion_1506705', content=u'programa especial ropa sensible planchado f\\xc3\\xa1cil funci\\xc3\\xb3n especial tiempo cercano punto fuerte se\\xc3\\xb1al ac\\xc3\\xbastico lugar visible carga m\\xc3\\xa1ximo consumo m\\xc3\\xa1ximo', label=5)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regresa una lista\n",
    "spark_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[id: string, content: string, label: bigint],\n",
       " DataFrame[id: string, content: string, label: bigint])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross validation\n",
    "\n",
    "(df_train, df_test) = spark_df.randomSplit([0.8, 0.2])\n",
    "(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, content: string, label: bigint, tokens: array<string>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#breaking a stream of text up into tokens or other elements \n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='content', outputCol='tokens')\n",
    "tokensData = tokenizer.transform(spark_df)\n",
    "tokensData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: string, content: string, label: bigint, tokens: array<string>]\n",
      "DataFrame[id: string, content: string, label: bigint, tokens: array<string>, content_tf: vector]\n",
      "DataFrame[id: string, content: string, label: bigint, tokens: array<string>, content_tf: vector, content_tfidf: vector]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol='content', outputCol='tokens')\n",
    "df_train_words = tokenizer.transform(df_train)\n",
    "\n",
    "# Hashing Term-Frequency\n",
    "from pyspark.ml.feature import HashingTF\n",
    "hashing_tf = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol='content_tf', numFeatures=10000)\n",
    "df_train_tf = hashing_tf.transform(df_train_words)\n",
    "\n",
    "# Inverse Document Frequency\n",
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"content_tfidf\")\n",
    "idf_model = idf.fit(df_train_tf) # fit to build the model on all the data, and then apply it line by line\n",
    "df_train_tfidf = idf_model.transform(df_train_tf)\n",
    "\n",
    "print df_train_words\n",
    "print df_train_tf\n",
    "print df_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                  id|             content|label|              tokens|          content_tf|       content_tfidf|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|AEG_Electrolux_60...|programa especial...|    5|[programa, especi...|(10000,[205,226,3...|(10000,[205,226,3...|\n",
      "|AEG_Electrolux_62...|carga superior pu...|    4|[carga, superior,...|(10000,[596,1150,...|(10000,[596,1150,...|\n",
      "|AEG_Electrolux_L6...|   modelo electrolux|    4|[modelo, electrolux]|(10000,[614,1939]...|(10000,[614,1939]...|\n",
      "|AEG_Electrolux_L6...|clasificaciÃ³n en...|    4|[clasificaciã³n, ...|(10000,[3465,3731...|(10000,[3465,3731...|\n",
      "|AEG_Electrolux_L6...|habitaciÃ³n princ...|    4|[habitaciã³n, pri...|(10000,[565,2075,...|(10000,[565,2075,...|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_tfidf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, content: string, label: bigint, tokens: array<string>, content_tf: vector, content_tfidf: vector, target_indexed: double]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing the label\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "string_indexer = StringIndexer(inputCol='label', outputCol='target_indexed')\n",
    "string_indexer_model = string_indexer.fit(df_train_tfidf)\n",
    "df_train_final = string_indexer_model.transform(df_train_tfidf)\n",
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training a Decision Tree on training set\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol=idf.getOutputCol(), labelCol=string_indexer.getOutputCol())\n",
    "dt_model = dt.fit(df_train_final)\n",
    "\n",
    "# Transform the test set\n",
    "df_test_words = tokenizer.transform(df_test)\n",
    "df_test_tf = hashing_tf.transform(df_test_words)\n",
    "df_test_tfidf = idf_model.transform(df_test_tf)\n",
    "df_test_final = string_indexer_model.transform(df_test_tfidf)\n",
    "\n",
    "# Preditions on the test set\n",
    "df_test_pred = dt_model.transform(df_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+--------------------+\n",
      "|                  id|label|prediction|         probability|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "|AEG_Electrolux_L1...|    5|       1.0|[0.33992094861660...|\n",
      "|AEG_Electrolux_L6...|    5|       0.0|[0.43514328808446...|\n",
      "|AEG_Electrolux_L7...|    4|       1.0|[0.33992094861660...|\n",
      "|AEG_Electrolux_L_...|    4|       1.0|[0.1,0.8,0.1,0.0,...|\n",
      "|AEG_Electrolux_L_...|    4|       1.0|[0.33992094861660...|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_pred.select('id', 'label', 'prediction', 'probability').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.mllib.classification import SVMModel\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Instanciate all the Estimators and Transformers necessary\n",
    "tokenizer = Tokenizer(inputCol='content', outputCol='content_words')\n",
    "hashing_tf = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol='content_tf', numFeatures=10000)\n",
    "idf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"content_tfidf\")\n",
    "string_indexer = StringIndexer(inputCol='label', outputCol='label_indexed')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=idf.getOutputCol(), labelCol=string_indexer.getOutputCol())\n",
    "\n",
    "\n",
    "\n",
    "# Instanciate a Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, \n",
    "                            hashing_tf, \n",
    "                            idf, \n",
    "                            string_indexer, \n",
    "                            dt])\n",
    "\n",
    "# Transform the data and train the classifier on the training set\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "\n",
    "# Transform the data and perform predictions on the test set\n",
    "df_test_pred = pipeline_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|                  id|             content|label|       content_words|          content_tf|       content_tfidf|label_indexed|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|AEG_Electrolux_L1...|carga superior fo...|    5|[carga, superior,...|(10000,[596,1150,...|(10000,[596,1150,...|          0.0|[86.0,137.0,26.0,...|[0.33992094861660...|       1.0|\n",
      "|AEG_Electrolux_L6...|ficha tecnica pro...|    5|[ficha, tecnica, ...|(10000,[5657,6679...|(10000,[5657,6679...|          0.0|[577.0,468.0,126....|[0.43514328808446...|       0.0|\n",
      "|AEG_Electrolux_L7...|clasificaciÃ³n en...|    4|[clasificaciã³n, ...|(10000,[1144,1909...|(10000,[1144,1909...|          1.0|[86.0,137.0,26.0,...|[0.33992094861660...|       1.0|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_pred.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47680890538033394"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Instanciate a MulticlassClassificationEvaluator with precision metric\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label_indexed', \n",
    "                                              metricName='precision')\n",
    "\n",
    "# Evaluate the predictions done on the test set\n",
    "evaluator.evaluate(df_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tune hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47680890538033394"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# Instanciation of a ParamGridBuilder\n",
    "\n",
    "grid = (ParamGridBuilder()\n",
    "        .baseOn([evaluator.metricName, 'precision'])\n",
    "        .addGrid(dt.maxDepth, [10, 30])\n",
    "        .build())\n",
    "\n",
    "# Instanciation of a CrossValidator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=grid, evaluator=evaluator)\n",
    "\n",
    "# Transform the data and train the classifier on the training set\n",
    "cv_model = cv.fit(df_train)\n",
    "\n",
    "# Transform the data and perform predictions on the test set\n",
    "df_test_pred = cv_model.transform(df_test)\n",
    "\n",
    "# Evaluate the predictions done on the test set\n",
    "evaluator.evaluate(df_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
